# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2026-02-21T09:00:56.836011Z","iopub.execute_input":"2026-02-21T09:00:56.836785Z","iopub.status.idle":"2026-02-21T09:01:00.429820Z","shell.execute_reply.started":"2026-02-21T09:00:56.836753Z","shell.execute_reply":"2026-02-21T09:01:00.428808Z"}}
# ================= ç¯å¢ƒå‡†å¤‡ï¼šå®‰è£…ä¾èµ– =================
# å®‰è£…åŒ…å« solutions API çš„ç¨³å®šç‰ˆæœ¬
!pip install mediapipe opencv-python -q

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2026-02-21T09:01:00.439442Z","iopub.status.idle":"2026-02-21T09:01:00.439799Z","shell.execute_reply.started":"2026-02-21T09:01:00.439605Z","shell.execute_reply":"2026-02-21T09:01:00.439627Z"}}
import torch
import random
import os
import numpy as np
from IPython.display import Image, Video
import cv2
import mediapipe as mp

# ================= 1. åŸºç¡€é…ç½®ä¸ç¯å¢ƒè®¾ç½® =================
SEED = 42
DEVICE_ID = 0          

INPUT_VIDEO_PATH = '/kaggle/input/datasets/liuweiq/daxiaonailong/caixunkun.mp4'
INPUT_BASENAME = os.path.splitext(os.path.basename(INPUT_VIDEO_PATH))[0]
OUTPUT_DIR = '/kaggle/working/runs/pose/predict'
OUTPUT_VIDEO_PATH = os.path.join(OUTPUT_DIR, f'{INPUT_BASENAME}_black_mesh.mp4')
FINAL_MP4_PATH = f'compressed_{INPUT_BASENAME}.mp4'

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)
print(f"ğŸ“‚ è¾“å‡ºç›®å½•å·²å°±ç»ª: {OUTPUT_DIR}")

# æ¨ç†å‚æ•°ï¼ˆå½“å‰æœªç›´æ¥ä½¿ç”¨ï¼Œä¿ç•™ä¾›æ‰©å±•ï¼‰
CONF_THRESHOLD = 0.1    
IOU_THRESHOLD = 0.6      
VID_STRIDE = 1

# %% [code] {"execution":{"iopub.status.busy":"2026-02-21T09:01:00.440651Z","iopub.status.idle":"2026-02-21T09:01:00.440894Z","shell.execute_reply.started":"2026-02-21T09:01:00.440782Z","shell.execute_reply":"2026-02-21T09:01:00.440797Z"},"jupyter":{"outputs_hidden":false}}
# ================= å›ºå®šéšæœºç§å­ä»¥ä¿è¯å¯å¤ç°æ€§ =================
def seed_everything(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True 
    torch.backends.cudnn.benchmark = False

seed_everything(SEED)

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2026-02-21T09:01:00.443855Z","iopub.status.idle":"2026-02-21T09:01:00.444169Z","shell.execute_reply.started":"2026-02-21T09:01:00.444046Z","shell.execute_reply":"2026-02-21T09:01:00.444061Z"}}
# ================= 2. åˆå§‹åŒ–MediaPipe Holisticï¼ˆæŒ‰ç…§å®˜æ–¹æ–‡æ¡£æ ¼å¼ï¼‰ =================
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles
mp_holistic = mp.solutions.holistic

# ================= 3. è§†é¢‘è¯»å†™åˆå§‹åŒ–ä¸å¤„ç† =================
cap = cv2.VideoCapture(INPUT_VIDEO_PATH)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = cap.get(cv2.CAP_PROP_FPS)

fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (width, height))

print(f"ğŸ¬ å¼€å§‹ä½¿ç”¨ MediaPipe Holistic æå–å…¨èº«ã€å§¿æ€+é¢éƒ¨+æ‰‹åŠ¿ã€‘ç½‘æ ¼...")

# ================= 4. ä½¿ç”¨ with è¯­å¥å¤„ç†è§†é¢‘æµï¼ˆå®˜æ–¹æ¨èæ–¹å¼ï¼‰=================
frame_count = 0
with mp_holistic.Holistic(
    static_image_mode=False,
    model_complexity=1,
    smooth_landmarks=True,
    enable_segmentation=False,
    refine_face_landmarks=False,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5) as holistic:
    
    while cap.isOpened():
        success, image = cap.read()
        if not success:
            print("è§†é¢‘å¤„ç†å®Œæˆ")
            break
            
        frame_count += 1
        
        # To improve performance, optionally mark the image as not writeable to pass by reference.
        image.flags.writeable = False
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = holistic.process(image)
        
        # åˆ›å»ºçº¯é»‘ç”»å¸ƒç”¨äºç»˜åˆ¶éª¨æ¶
        black_canvas = np.zeros((height, width, 3), dtype=np.uint8)

        # Draw face landmarks
        mp_drawing.draw_landmarks(
            black_canvas,
            results.face_landmarks,
            mp_holistic.FACEMESH_TESSELATION,
            landmark_drawing_spec=None,
            connection_drawing_spec=mp_drawing_styles
            .get_default_face_mesh_tesselation_style())
        
        mp_drawing.draw_landmarks(
            black_canvas,
            results.face_landmarks,
            mp_holistic.FACEMESH_CONTOURS,
            landmark_drawing_spec=None,
            connection_drawing_spec=mp_drawing_styles
            .get_default_face_mesh_contours_style())

        # Draw pose landmarks
        mp_drawing.draw_landmarks(
            black_canvas,
            results.pose_landmarks,
            mp_holistic.POSE_CONNECTIONS,
            landmark_drawing_spec=mp_drawing_styles
            .get_default_pose_landmarks_style())

        # Draw left hand landmarks
        mp_drawing.draw_landmarks(
            black_canvas,
            results.left_hand_landmarks,
            mp_holistic.HAND_CONNECTIONS,
            mp_drawing_styles.get_default_hand_landmarks_style(),
            mp_drawing_styles.get_default_hand_connections_style())

        # Draw right hand landmarks
        mp_drawing.draw_landmarks(
            black_canvas,
            results.right_hand_landmarks,
            mp_holistic.HAND_CONNECTIONS,
            mp_drawing_styles.get_default_hand_landmarks_style(),
            mp_drawing_styles.get_default_hand_connections_style())

        out.write(black_canvas)
        print(f"å¤„ç†è¿›åº¦: ç¬¬ {frame_count} å¸§", end='\r')

cap.release()
out.release()
print(f"\nâœ… MediaPipe Holistic å…¨èº«å§¿æ€è§†é¢‘ç”Ÿæˆå®Œæˆï¼å·²ä¿å­˜è‡³ {OUTPUT_VIDEO_PATH}")

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2026-02-21T09:01:00.445275Z","iopub.status.idle":"2026-02-21T09:01:00.445716Z","shell.execute_reply.started":"2026-02-21T09:01:00.445437Z","shell.execute_reply":"2026-02-21T09:01:00.445459Z"}}
# ================= 5. FFmpeg éŸ³è§†é¢‘åˆå¹¶ä¸å‹ç¼© =================
print("æ­£åœ¨åˆå¹¶éŸ³é¢‘ä¸ç”»é¢...")
ffmpeg_cmd = (
    f'ffmpeg -y '
    f'-i {OUTPUT_VIDEO_PATH} '         # è§†é¢‘æºï¼šå§¿æ€æ£€æµ‹ç”Ÿæˆçš„ç”»é¢
    f'-i {INPUT_VIDEO_PATH} '          # éŸ³é¢‘æºï¼šåŸå§‹è¾“å…¥è§†é¢‘
    f'-map 0:v:0 -map 1:a:0 '
    f'-vcodec libx264 -preset ultrafast -vf scale=1080:-2 '
    f'-c:a copy -shortest '
    f'{FINAL_MP4_PATH}'
)
os.system(ffmpeg_cmd)
print(f"âœ… åˆå¹¶å‹ç¼©å®Œæˆï¼æœ€ç»ˆæ–‡ä»¶: {FINAL_MP4_PATH}")

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2026-02-21T09:01:00.447019Z","iopub.status.idle":"2026-02-21T09:01:00.447347Z","shell.execute_reply.started":"2026-02-21T09:01:00.447181Z","shell.execute_reply":"2026-02-21T09:01:00.447196Z"}}
# ================= 6. åœ¨Notebookä¸­å±•ç¤ºæœ€ç»ˆè§†é¢‘ =================
display(Video(FINAL_MP4_PATH, embed=True, width=640))