{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3cfda68a-d94f-4869-af30-3810bbda792d",
    "_uuid": "f6a0192a-068c-4794-a558-92699409fd50",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.024671,
     "end_time": "2021-10-09T06:31:15.364456",
     "exception": false,
     "start_time": "2021-10-09T06:31:15.339785",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h1 style=\"text-align:center;font-weight: bold\">GAN</h1>\n",
    "    <h3 style=\"text-align:left;font-weight: bold\">A generative adversarial network is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in 2014. Two neural networks contest with each other in a game. Given a training set, this technique learns to generate new data with the same statistics as the training set.</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "185b050c-45f1-4b73-a064-4d4073816aa5",
    "_uuid": "c17b1ae3-930b-4b9f-b13e-f329f70b4086",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:03.639124Z",
     "iopub.status.busy": "2025-01-12T06:34:03.638765Z",
     "iopub.status.idle": "2025-01-12T06:34:16.282299Z",
     "shell.execute_reply": "2025-01-12T06:34:16.281612Z",
     "shell.execute_reply.started": "2025-01-12T06:34:03.639072Z"
    },
    "id": "yoj6U2rmjiS-",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.625925,
     "end_time": "2021-10-09T06:31:24.764729",
     "exception": false,
     "start_time": "2021-10-09T06:31:23.138804",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torchsummary\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8b33fe96-0dab-4d66-b95c-5c981238f4c6",
    "_uuid": "90dec837-50c8-43cc-8c40-3549d5801e41",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:16.316158Z",
     "iopub.status.busy": "2025-01-12T06:34:16.315904Z",
     "iopub.status.idle": "2025-01-12T06:34:16.369325Z",
     "shell.execute_reply": "2025-01-12T06:34:16.368515Z",
     "shell.execute_reply.started": "2025-01-12T06:34:16.316131Z"
    },
    "id": "xVXC_q2ekuf8",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.079089,
     "end_time": "2021-10-09T06:31:24.988503",
     "exception": false,
     "start_time": "2021-10-09T06:31:24.909414",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 16\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "37fc4302-5f7d-45e3-a585-3549c4be9a26",
    "_uuid": "c9866c84-e77d-4434-91ee-bf2ad29a5a04",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:16.370772Z",
     "iopub.status.busy": "2025-01-12T06:34:16.370400Z",
     "iopub.status.idle": "2025-01-12T06:34:16.388456Z",
     "shell.execute_reply": "2025-01-12T06:34:16.387796Z",
     "shell.execute_reply.started": "2025-01-12T06:34:16.370732Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "\n",
    "def process_images_in_directory(source_dir, target_dir):\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    # 遍历源目录中的文件\n",
    "    for file_name in os.listdir(source_dir):\n",
    "        file_path = os.path.join(source_dir, file_name)\n",
    "\n",
    "        # 检查文件是否是图片\n",
    "        if file_name.lower().endswith(\n",
    "            (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".tif\")\n",
    "        ):\n",
    "            # 打开图片\n",
    "            img = Image.open(file_path)\n",
    "\n",
    "            # 保存原始图片到目标目录\n",
    "            original_save_path = os.path.join(target_dir, f\"original_{file_name}\")\n",
    "            img.save(original_save_path)\n",
    "\n",
    "            # 上下翻转\n",
    "            flipped_up_down = ImageOps.flip(img)\n",
    "            flipped_up_down_save_path = os.path.join(\n",
    "                target_dir, f\"flipped_ud_{file_name}\"\n",
    "            )\n",
    "            flipped_up_down.save(flipped_up_down_save_path)\n",
    "\n",
    "            # 左右翻转\n",
    "            flipped_left_right = ImageOps.mirror(img)\n",
    "            flipped_left_right_save_path = os.path.join(\n",
    "                target_dir, f\"flipped_lr_{file_name}\"\n",
    "            )\n",
    "            flipped_left_right.save(flipped_left_right_save_path)\n",
    "\n",
    "            # 90度旋转\n",
    "            rotated_90 = img.rotate(90)  # 逆时针旋转90度\n",
    "            rotated_90_save_path = os.path.join(target_dir, f\"rotated_90_{file_name}\")\n",
    "            rotated_90.save(rotated_90_save_path)\n",
    "\n",
    "            # 270度旋转\n",
    "            rotated_270 = img.rotate(270)  # 逆时针旋转270度\n",
    "            rotated_270_save_path = os.path.join(target_dir, f\"rotated_270_{file_name}\")\n",
    "            rotated_270.save(rotated_270_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "88cfb87c-2c50-47bc-9713-23327eb190ab",
    "_uuid": "6f33ed63-0643-42c1-84e7-41a230203cbd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:16.389651Z",
     "iopub.status.busy": "2025-01-12T06:34:16.389327Z",
     "iopub.status.idle": "2025-01-12T06:34:24.236402Z",
     "shell.execute_reply": "2025-01-12T06:34:24.235562Z",
     "shell.execute_reply.started": "2025-01-12T06:34:16.389623Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# 原始目录和目标目录\n",
    "source_dir = \"/kaggle/input/efficientnet-data/my_label_data/0\"\n",
    "target_dir = \"./train/data\"\n",
    "\n",
    "# 创建目标目录\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "process_images_in_directory(source_dir, target_dir)\n",
    "process_images_in_directory(\n",
    "    f\"/kaggle/input/efficientnet-data/efficient_net_data_me/cropped_objects/0\",\n",
    "    f\"{target_dir}\",\n",
    ")\n",
    "process_images_in_directory(\n",
    "    f\"/kaggle/input/efficientnet-data/efficient2/cropped_objects/0\", f\"{target_dir}\"\n",
    ")\n",
    "\n",
    "# shutil.copytree('/kaggle/input/efficientnet-data/efficient_net_data_me/cropped_objects/0', f'{target_dir}', dirs_exist_ok=True)\n",
    "# shutil.copytree('/kaggle/input/efficientnet-data/efficient2/cropped_objects/0', f'{target_dir}', dirs_exist_ok=True)\n",
    "\n",
    "image_count = sum(\n",
    "    1\n",
    "    for file_name in os.listdir(target_dir)\n",
    "    if file_name.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".tif\"))\n",
    ")\n",
    "\n",
    "# 打印总数\n",
    "print(f\"Total images in the directory: {image_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c112a932-0942-41d7-8e10-ba77dc4a8bbf",
    "_uuid": "b049533a-c11b-4be7-9f12-8d45ece96dee",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:24.237433Z",
     "iopub.status.busy": "2025-01-12T06:34:24.237151Z",
     "iopub.status.idle": "2025-01-12T06:34:24.247863Z",
     "shell.execute_reply": "2025-01-12T06:34:24.247128Z",
     "shell.execute_reply.started": "2025-01-12T06:34:24.237411Z"
    },
    "id": "rmKRUtX6kwt1",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 12.148366,
     "end_time": "2021-10-09T06:31:37.214299",
     "exception": false,
     "start_time": "2021-10-09T06:31:25.065933",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=\"./train\", transform=train_transform\n",
    ")  # 原始为../input/efficientnet-data/test/\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Grayscale(num_output_channels=1),  # 转换为灰度图像\n",
    "#     transforms.Resize((16, 16)),  # 调整为目标分辨率\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.5], [0.5])  # 对灰度图像进行归一化\n",
    "# ])\n",
    "# train_dataset = datasets.ImageFolder(root='./train', transform=train_transform) #原始为../input/efficientnet-data/test/\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eb338297-2160-4deb-9a0e-e914e251b4da",
    "_uuid": "7069c276-e014-4279-ac92-d7be7d48f8a4",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.025809,
     "end_time": "2021-10-09T06:31:37.266513",
     "exception": false,
     "start_time": "2021-10-09T06:31:37.240704",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h1 style=\"text-align:center;font-weight: bold;\">Exploratory Data Analysis</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d7d2bd2c-77d8-4f58-ba96-8f650e57469c",
    "_uuid": "969de3ef-3d59-4d2b-851b-f4f9e7aa87e0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:24.250644Z",
     "iopub.status.busy": "2025-01-12T06:34:24.250435Z",
     "iopub.status.idle": "2025-01-12T06:34:24.710678Z",
     "shell.execute_reply": "2025-01-12T06:34:24.708328Z",
     "shell.execute_reply.started": "2025-01-12T06:34:24.250626Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034789,
     "end_time": "2021-10-09T06:31:37.327581",
     "exception": false,
     "start_time": "2021-10-09T06:31:37.292792",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "# 显示图像的函数\n",
    "def show_images(images, nrow=8, figsize=(10, 10)):\n",
    "    # 创建图像网格\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_xticks([])  # 隐藏x轴刻度\n",
    "    ax.set_yticks([])  # 隐藏y轴刻度\n",
    "\n",
    "    # 将图片网格的大小调整并转置为 (height, width, channels)\n",
    "    grid_img = make_grid(images, nrow=nrow).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # 显示图片\n",
    "    ax.imshow(grid_img)\n",
    "\n",
    "\n",
    "# 显示批次图像的函数\n",
    "def show_batch(dl, n_images=64, nrow=8):\n",
    "    # 只显示部分图像\n",
    "    for images, _ in dl:\n",
    "        # 只取前 n_images 张图像\n",
    "        images = images[:n_images]\n",
    "        show_images(images, nrow=nrow)\n",
    "        break  # 只显示一个批次的图像\n",
    "\n",
    "\n",
    "# 使用 train_loader 来展示图像\n",
    "show_batch(train_loader, n_images=64, nrow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "67a898fe-caa2-4870-bd2b-4fc6c24a2476",
    "_uuid": "1750cd4d-e755-4cb4-9af0-7b44254896f9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:24.717565Z",
     "iopub.status.busy": "2025-01-12T06:34:24.714841Z",
     "iopub.status.idle": "2025-01-12T06:34:24.726048Z",
     "shell.execute_reply": "2025-01-12T06:34:24.724925Z",
     "shell.execute_reply.started": "2025-01-12T06:34:24.717521Z"
    },
    "id": "0ImLVM7lk2du",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.04636,
     "end_time": "2021-10-09T06:31:39.249683",
     "exception": false,
     "start_time": "2021-10-09T06:31:39.203323",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_shape = (3, 64, 64)\n",
    "image_dim = int(np.prod(image_shape))\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5277c9ec-490a-4952-af78-85e444637949",
    "_uuid": "b5ab7922-b70a-4ba4-9b2e-fcae568e7bfc",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.037989,
     "end_time": "2021-10-09T06:31:39.325346",
     "exception": false,
     "start_time": "2021-10-09T06:31:39.287357",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h2 style=\"text-align:center;font-weight: bold;\">Initializing Weights</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3318f1fe-ede0-4a2b-a17f-8616cb5c7b64",
    "_uuid": "9429989a-2724-46a7-86ef-df8158fad3b3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:24.730013Z",
     "iopub.status.busy": "2025-01-12T06:34:24.729569Z",
     "iopub.status.idle": "2025-01-12T06:34:24.741828Z",
     "shell.execute_reply": "2025-01-12T06:34:24.741240Z",
     "shell.execute_reply.started": "2025-01-12T06:34:24.729975Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.046865,
     "end_time": "2021-10-09T06:31:39.485146",
     "exception": false,
     "start_time": "2021-10-09T06:31:39.438281",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        torch.nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a6c5341a-4d5b-4e98-a0f4-e6b87df89d15",
    "_uuid": "16bca70b-5df7-40cf-9e98-a729f5149c77",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.037616,
     "end_time": "2021-10-09T06:31:39.560468",
     "exception": false,
     "start_time": "2021-10-09T06:31:39.522852",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h2 style=\"text-align:center;font-weight: bold;\">Generator Network</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "683afb83-a4b3-42f7-9be3-4864658e9634",
    "_uuid": "e72d7aaa-ea60-43a2-81f5-a8cd84f83596",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:24.742800Z",
     "iopub.status.busy": "2025-01-12T06:34:24.742562Z",
     "iopub.status.idle": "2025-01-12T06:34:24.758634Z",
     "shell.execute_reply": "2025-01-12T06:34:24.757816Z",
     "shell.execute_reply.started": "2025-01-12T06:34:24.742768Z"
    },
    "id": "_gw3SMN7jtOB",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.051132,
     "end_time": "2021-10-09T06:31:39.649246",
     "exception": false,
     "start_time": "2021-10-09T06:31:39.598114",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.main = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(latent_dim, 64 * 8, 4, 1, 0, bias=False),\n",
    "#             nn.BatchNorm2d(64 * 8),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(64 * 8, 64 * 4, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(64 * 4),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(64 * 4, 64 * 2, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(64 * 2),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(64 * 2, 64, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(Tru|e),\n",
    "#             nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         output = self.main(input)\n",
    "#         return output\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        # 主路径：上采样 + 卷积块\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False),  # 上采样\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        # 跳跃连接：直接上采样 + 1x1 卷积\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False),\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)  # 跳跃连接\n",
    "        block_output = self.block(x)  # 主路径\n",
    "        return F.relu(block_output + shortcut, inplace=True)  # 输出\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    基于 ResNet 的生成器，生成分辨率为 64x64 的图像。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(Generator, self).__init__()\n",
    "        # 初始映射层\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                latent_dim, 512, kernel_size=4, stride=1, padding=0, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # 残差块\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            ResidualBlock(512, 256),  # 4x4 -> 8x8\n",
    "            ResidualBlock(256, 128),  # 8x8 -> 16x16\n",
    "            ResidualBlock(128, 64),  # 16x16 -> 32x32\n",
    "        )\n",
    "        # 输出层\n",
    "        self.final_conv = nn.ConvTranspose2d(\n",
    "            64, 3, kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )  # 32x32 -> 64x64\n",
    "        self.final_activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.initial(z)\n",
    "        x = self.res_blocks(x)\n",
    "        x = self.final_conv(x)\n",
    "        x = self.final_activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, latent_dim):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.main = nn.Sequential(\n",
    "#             # 输入: latent_dim x 1 x 1 -> 64 * 8 x 4 x 4\n",
    "#             nn.ConvTranspose2d(latent_dim, 64 * 8, 4, 1, 0, bias=False),\n",
    "#             nn.BatchNorm2d(64 * 8),\n",
    "#             nn.ReLU(True),\n",
    "#             # 64 * 8 x 4 x 4 -> 64 * 4 x 8 x 8\n",
    "#             nn.ConvTranspose2d(64 * 8, 64 * 4, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(64 * 4),\n",
    "#             nn.ReLU(True),\n",
    "#             # 64 * 4 x 8 x 8 -> 64 * 2 x 16 x 16\n",
    "#             nn.ConvTranspose2d(64 * 4, 1, 4, 2, 1, bias=False),\n",
    "#             nn.Tanh()  # 将输出归一化到 [-1, 1]\n",
    "#         )\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9a44af85-878c-4916-a3b3-5949afc423ce",
    "_uuid": "d01c19d6-8a0e-4fc3-97a8-392a6fb1b82d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:24.759643Z",
     "iopub.status.busy": "2025-01-12T06:34:24.759436Z",
     "iopub.status.idle": "2025-01-12T06:34:25.036508Z",
     "shell.execute_reply": "2025-01-12T06:34:25.035660Z",
     "shell.execute_reply.started": "2025-01-12T06:34:24.759626Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.374826,
     "end_time": "2021-10-09T06:31:43.061517",
     "exception": false,
     "start_time": "2021-10-09T06:31:39.686691",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "generator.apply(weights_init)\n",
    "print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "db59897a-0fc2-432f-84ff-383e71116d45",
    "_uuid": "d99d6a53-2b0a-49a2-936c-c43c7f831b23",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:25.037548Z",
     "iopub.status.busy": "2025-01-12T06:34:25.037336Z",
     "iopub.status.idle": "2025-01-12T06:34:25.703458Z",
     "shell.execute_reply": "2025-01-12T06:34:25.702520Z",
     "shell.execute_reply.started": "2025-01-12T06:34:25.037529Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.616425,
     "end_time": "2021-10-09T06:31:43.756299",
     "exception": false,
     "start_time": "2021-10-09T06:31:43.139874",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "summary(generator, (latent_dim, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "018303e4-119b-4235-8a78-9af0e92144f7",
    "_uuid": "0fbdff18-cfe8-49f2-8094-9fa0af04012d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.038779,
     "end_time": "2021-10-09T06:31:43.835699",
     "exception": false,
     "start_time": "2021-10-09T06:31:43.79692",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h2 style=\"text-align:center;font-weight: bold;\">Descriminator Network</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8dc7f45e-91e8-47d4-8908-0ef0e052e7ca",
    "_uuid": "21e70dc5-1531-4e0f-872a-d83a1e9128dc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:25.704989Z",
     "iopub.status.busy": "2025-01-12T06:34:25.704654Z",
     "iopub.status.idle": "2025-01-12T06:34:25.711359Z",
     "shell.execute_reply": "2025-01-12T06:34:25.710514Z",
     "shell.execute_reply.started": "2025-01-12T06:34:25.704955Z"
    },
    "id": "xPEMXbaJCPsQ",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.052823,
     "end_time": "2021-10-09T06:31:43.927067",
     "exception": false,
     "start_time": "2021-10-09T06:31:43.874244",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils import spectral_norm\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(3, 64, 4, 2, 1, bias=False)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            spectral_norm(nn.Conv2d(64, 128, 4, 2, 1, bias=False)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            spectral_norm(nn.Conv2d(128, 256, 4, 2, 1, bias=False)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            spectral_norm(nn.Conv2d(256, 512, 4, 2, 1, bias=False)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.main = nn.Sequential(\n",
    "#             # 输入: 16x16 -> 8x8\n",
    "#             nn.Conv2d(1, 64, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "#             # 8x8 -> 4x4\n",
    "#             nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "#             # 4x4 -> 2x2\n",
    "#             nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "#             # 2x2 -> 1x1\n",
    "#             nn.Conv2d(256, 512, 2, 1, 0, bias=False),  # 修改 kernel_size 为 2\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "#             # 输出标量\n",
    "#             nn.Conv2d(512, 1, 1, 1, 0, bias=False),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         return self.main(input).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "daf4e64b-b6d7-4408-9b12-f8d40028e6be",
    "_uuid": "3764bb87-4a65-45cf-bb52-a1d720f201aa",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:25.712354Z",
     "iopub.status.busy": "2025-01-12T06:34:25.712072Z",
     "iopub.status.idle": "2025-01-12T06:34:25.781981Z",
     "shell.execute_reply": "2025-01-12T06:34:25.781263Z",
     "shell.execute_reply.started": "2025-01-12T06:34:25.712332Z"
    },
    "id": "1HJv-CnSkIuN",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.071596,
     "end_time": "2021-10-09T06:31:44.037229",
     "exception": false,
     "start_time": "2021-10-09T06:31:43.965633",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "discriminator.apply(weights_init)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c7d6c54e-e089-41f0-af22-4ac6cc590584",
    "_uuid": "bf9e8634-0b0f-491a-95c8-b1320269679f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:25.783030Z",
     "iopub.status.busy": "2025-01-12T06:34:25.782779Z",
     "iopub.status.idle": "2025-01-12T06:34:25.974784Z",
     "shell.execute_reply": "2025-01-12T06:34:25.974038Z",
     "shell.execute_reply.started": "2025-01-12T06:34:25.783009Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.0621,
     "end_time": "2021-10-09T06:31:44.143231",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.081131",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "summary(discriminator, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0b94231b-b024-4b15-94e8-71971b8ad725",
    "_uuid": "a188ab9d-59fc-4184-8cd1-5aea5068cf96",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:25.975704Z",
     "iopub.status.busy": "2025-01-12T06:34:25.975502Z",
     "iopub.status.idle": "2025-01-12T06:34:25.979250Z",
     "shell.execute_reply": "2025-01-12T06:34:25.978563Z",
     "shell.execute_reply.started": "2025-01-12T06:34:25.975686Z"
    },
    "id": "RFxQC7T0laZi",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.045481,
     "end_time": "2021-10-09T06:31:44.228253",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.182772",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "adversarial_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f037fae9-333e-4721-bc6d-a0aa20d2c854",
    "_uuid": "e8908d40-820b-44d8-8204-d6b4c72f6af6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:25.980366Z",
     "iopub.status.busy": "2025-01-12T06:34:25.980044Z",
     "iopub.status.idle": "2025-01-12T06:34:25.994404Z",
     "shell.execute_reply": "2025-01-12T06:34:25.993566Z",
     "shell.execute_reply.started": "2025-01-12T06:34:25.980336Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.046164,
     "end_time": "2021-10-09T06:31:44.312994",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.26683",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output, label):\n",
    "    gen_loss = adversarial_loss(fake_output, label)\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "64b31e26-6dfb-4ba5-a8cc-488762747480",
    "_uuid": "1e0132b4-158d-47ee-bd1c-3af18c3f4d6b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.038516,
     "end_time": "2021-10-09T06:31:44.390559",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.352043",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "## The generator_loss function is fed two parameters:\n",
    "\n",
    "- fake_output: Output predictions from the discriminator, when fed generator-produced images.\n",
    "- label: Ground truth labels (1), for you would like the generator to fool the discriminator and produce real images. Hence, the labels would be one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a069ea90-370c-4639-a58b-7ab316cf34e9",
    "_uuid": "816724d6-95f1-49b8-8f5e-2eee729d9dbd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:25.995456Z",
     "iopub.status.busy": "2025-01-12T06:34:25.995214Z",
     "iopub.status.idle": "2025-01-12T06:34:26.008237Z",
     "shell.execute_reply": "2025-01-12T06:34:26.007553Z",
     "shell.execute_reply.started": "2025-01-12T06:34:25.995436Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.074971,
     "end_time": "2021-10-09T06:31:44.503934",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.428963",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "    def discriminator_loss(output, label):\n",
    "        disc_loss = adversarial_loss(output, label)\n",
    "        return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4c960509-e291-4ca8-8310-3f9430efe5f0",
    "_uuid": "87fa85df-7df4-4405-8889-02cc86c53690",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:26.009398Z",
     "iopub.status.busy": "2025-01-12T06:34:26.009098Z",
     "iopub.status.idle": "2025-01-12T06:34:26.022501Z",
     "shell.execute_reply": "2025-01-12T06:34:26.021680Z",
     "shell.execute_reply.started": "2025-01-12T06:34:26.009370Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F  # 导入 F 模块\n",
    "\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    return torch.mean(F.relu(1.0 - real_output)) + torch.mean(F.relu(1.0 + fake_output))\n",
    "\n",
    "\n",
    "def generator_loss(fake_output, label=None):\n",
    "    return -torch.mean(fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9c94f140-8cdf-4fc2-a823-2d38322ffe78",
    "_uuid": "533dd396-7df5-441c-a428-43fbed5b88f2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:26.023459Z",
     "iopub.status.busy": "2025-01-12T06:34:26.023262Z",
     "iopub.status.idle": "2025-01-12T06:34:26.037130Z",
     "shell.execute_reply": "2025-01-12T06:34:26.036487Z",
     "shell.execute_reply.started": "2025-01-12T06:34:26.023442Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real_data, fake_data, device):\n",
    "    \"\"\"\n",
    "    计算梯度惩罚项，确保判别器满足 Lipschitz 连续性。\n",
    "    :param critic: 判别器模型\n",
    "    :param real_data: 真实样本\n",
    "    :param fake_data: 生成样本\n",
    "    :param device: 当前设备\n",
    "    :return: 梯度惩罚值\n",
    "    \"\"\"\n",
    "    # 生成插值样本\n",
    "    batch_size = real_data.size(0)\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1, device=device)  # 随机权重\n",
    "    interpolates = alpha * real_data + (1 - alpha) * fake_data\n",
    "    interpolates.requires_grad_(True)\n",
    "\n",
    "    # 判别器对插值样本的输出\n",
    "    critic_output = critic(interpolates)\n",
    "\n",
    "    # 计算插值样本的梯度\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=critic_output,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones_like(critic_output, device=device),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    # 计算梯度范数和惩罚\n",
    "    gradients = gradients.view(batch_size, -1)  # 展平\n",
    "    gradient_norm = gradients.norm(2, dim=1)  # 计算 L2 范数\n",
    "    penalty = ((gradient_norm - 1) ** 2).mean()\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c76b96a6-466f-42be-94f7-c3a75a9dd855",
    "_uuid": "0ad0c93b-84bc-4e87-80c3-e29839e807f3",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.063915,
     "end_time": "2021-10-09T06:31:44.635401",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.571486",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "## The discriminator loss has:\n",
    "\n",
    "- real (original images) output predictions, ground truth label as 1\n",
    "- fake (generated images) output predictions, ground truth label as 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "49789e9f-4126-456b-b932-7858c7ec3cea",
    "_uuid": "b0d59200-95d1-48b3-a56c-a5eb94932909",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:26.038017Z",
     "iopub.status.busy": "2025-01-12T06:34:26.037827Z",
     "iopub.status.idle": "2025-01-12T06:34:26.051640Z",
     "shell.execute_reply": "2025-01-12T06:34:26.050808Z",
     "shell.execute_reply.started": "2025-01-12T06:34:26.038001Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.072788,
     "end_time": "2021-10-09T06:31:44.772757",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.699969",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(128, latent_dim, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3ce1f5d3-f52b-471e-8d38-f730360cbf3e",
    "_uuid": "6898a4d4-d37d-4bd5-aed6-a8cf777f723e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:26.052698Z",
     "iopub.status.busy": "2025-01-12T06:34:26.052479Z",
     "iopub.status.idle": "2025-01-12T06:34:26.066280Z",
     "shell.execute_reply": "2025-01-12T06:34:26.065351Z",
     "shell.execute_reply.started": "2025-01-12T06:34:26.052679Z"
    },
    "id": "sis4zEVQkLf_",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.077416,
     "end_time": "2021-10-09T06:31:44.914779",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.837363",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "G_optimizer = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "D_optimizer = optim.Adam(\n",
    "    discriminator.parameters(), lr=learning_rate * 0.08, betas=(0.5, 0.999)\n",
    ")  # 单个粒子使用0.3就可以了，分离使用0.04 单个粒子0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "864f35ec-4289-4139-8030-4c7c4472865e",
    "_uuid": "2a853f52-3849-4fdc-a779-d51eb1642260",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.040677,
     "end_time": "2021-10-09T06:31:46.648014",
     "exception": false,
     "start_time": "2021-10-09T06:31:46.607337",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h2 style=\"text-align:center;font-weight: bold;\">Training our network</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3d04ed1d-7beb-4562-a1aa-8f620d60c7dd",
    "_uuid": "484b32b7-3286-4f89-b774-239bb714b94d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:26.067396Z",
     "iopub.status.busy": "2025-01-12T06:34:26.067085Z",
     "iopub.status.idle": "2025-01-12T06:44:17.687251Z",
     "shell.execute_reply": "2025-01-12T06:44:17.686233Z",
     "shell.execute_reply.started": "2025-01-12T06:34:26.067368Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as F  # 用于 ReLU\n",
    "\n",
    "# 初始化\n",
    "D_loss_plot, G_loss_plot = [], []\n",
    "best_loss_diff = float(\"inf\")  # 初始化为无穷大\n",
    "\n",
    "# 定义保存路径\n",
    "os.makedirs(\"./t_weights\", exist_ok=True)\n",
    "os.makedirs(\"./images\", exist_ok=True)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    D_loss_list, G_loss_list = [], []\n",
    "\n",
    "    for index, (real_images, _) in enumerate(train_loader):\n",
    "        # ==================== 判别器训练 ====================\n",
    "        D_optimizer.zero_grad()\n",
    "        real_images = real_images.to(device)\n",
    "\n",
    "        # 生成假样本\n",
    "        noise_vector = torch.randn(real_images.size(0), latent_dim, 1, 1, device=device)\n",
    "        generated_image = generator(noise_vector)\n",
    "\n",
    "        # 判别器输出\n",
    "        real_output = discriminator(real_images)\n",
    "        fake_output = discriminator(generated_image.detach())\n",
    "\n",
    "        # 梯度惩罚\n",
    "        lambda_gp = 10  # 梯度惩罚权重\n",
    "        gp = gradient_penalty(\n",
    "            discriminator, real_images, generated_image.detach(), device\n",
    "        )\n",
    "\n",
    "        # 判别器损失（WGAN-GP）\n",
    "        D_loss = -torch.mean(real_output) + torch.mean(fake_output) + lambda_gp * gp\n",
    "        D_loss.backward()\n",
    "        D_loss_list.append(D_loss.item())\n",
    "        D_optimizer.step()\n",
    "\n",
    "        # ==================== 生成器训练 ====================\n",
    "        G_optimizer.zero_grad()\n",
    "\n",
    "        # 生成器的假样本输出\n",
    "        fake_output = discriminator(generated_image)\n",
    "\n",
    "        # 生成器损失\n",
    "        G_loss = -torch.mean(fake_output)\n",
    "        G_loss.backward()\n",
    "        G_loss_list.append(G_loss.item())\n",
    "        G_optimizer.step()\n",
    "\n",
    "    # 计算每个 epoch 的平均损失\n",
    "    avg_D_loss = torch.mean(torch.FloatTensor(D_loss_list))\n",
    "    avg_G_loss = torch.mean(torch.FloatTensor(G_loss_list))\n",
    "    loss_diff = abs(avg_D_loss - avg_G_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: [{epoch}/{num_epochs}]: D_loss: {avg_D_loss:.3f}, G_loss: {avg_G_loss:.3f}, Loss_Diff: {loss_diff:.3f}\"\n",
    "    )\n",
    "\n",
    "    # 保存损失\n",
    "    D_loss_plot.append(avg_D_loss)\n",
    "    G_loss_plot.append(avg_G_loss)\n",
    "\n",
    "    # 保存生成的图像\n",
    "    if epoch % 10 == 0:  # 每 10 个 epoch 保存一次样本\n",
    "        save_image(\n",
    "            generated_image.data[:10],\n",
    "            f\"./images/sample_{epoch}.png\",\n",
    "            nrow=5,\n",
    "            normalize=True,\n",
    "        )\n",
    "\n",
    "    # 保存最佳模型（基于损失差异）\n",
    "    if loss_diff < 0.7:\n",
    "        best_loss_diff = loss_diff\n",
    "        save_image(\n",
    "            generated_image.data[:3],\n",
    "            f\"./images/sample_{epoch}.png\",\n",
    "            nrow=5,\n",
    "            normalize=True,\n",
    "        )\n",
    "        torch.save(generator.state_dict(), \"./t_weights/best_generator.pth\")\n",
    "        torch.save(discriminator.state_dict(), \"./t_weights/best_discriminator.pth\")\n",
    "        print(f\"Best model saved at epoch {epoch} with Loss_Diff: {best_loss_diff:.3f}\")\n",
    "\n",
    "# 最后保存损失曲线\n",
    "torch.save(D_loss_plot, \"./t_weights/D_loss_plot.pth\")\n",
    "torch.save(G_loss_plot, \"./t_weights/G_loss_plot.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7225009f-6597-4411-9a71-718da7602b42",
    "_uuid": "da4b614d-4497-463d-86b6-d12c0a124466",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:17.688707Z",
     "iopub.status.busy": "2025-01-12T06:44:17.688454Z",
     "iopub.status.idle": "2025-01-12T06:44:18.007319Z",
     "shell.execute_reply": "2025-01-12T06:44:18.006452Z",
     "shell.execute_reply.started": "2025-01-12T06:44:17.688685Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(D_loss_plot, label=\"Discriminator Loss (D)\", color=\"red\", linewidth=2)\n",
    "plt.plot(G_loss_plot, label=\"Generator Loss (G)\", color=\"blue\", linewidth=2)\n",
    "\n",
    "# 添加标题和标签\n",
    "plt.title(\"GAN Training Loss\", fontsize=16)\n",
    "plt.xlabel(\"Epoch\", fontsize=14)\n",
    "plt.ylabel(\"Loss\", fontsize=14)\n",
    "\n",
    "# 添加图例\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "loss_diff = [abs(d - g) for d, g in zip(D_loss_plot, G_loss_plot)]\n",
    "plt.plot(loss_diff, label=\"Loss Difference\", color=\"green\", linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5ed1097d-e579-4a40-bdf5-b6e7b1395622",
    "_uuid": "45918610-178d-455c-be7b-54704cc83b2b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:18.010799Z",
     "iopub.status.busy": "2025-01-12T06:44:18.010577Z",
     "iopub.status.idle": "2025-01-12T06:44:18.014254Z",
     "shell.execute_reply": "2025-01-12T06:44:18.013545Z",
     "shell.execute_reply.started": "2025-01-12T06:44:18.010781Z"
    },
    "id": "LQLFEfpgkLjS",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 27904.411894,
     "end_time": "2021-10-09T14:16:51.099836",
     "exception": false,
     "start_time": "2021-10-09T06:31:46.687942",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# D_loss_plot, G_loss_plot = [], []\n",
    "# for epoch in range(1, num_epochs+1):\n",
    "\n",
    "#     D_loss_list, G_loss_list = [], []\n",
    "\n",
    "#     for index, (real_images, _) in enumerate(train_loader):\n",
    "#         D_optimizer.zero_grad()\n",
    "#         real_images = real_images.to(device)\n",
    "\n",
    "#         real_target = Variable(torch.ones(real_images.size(0)).to(device))\n",
    "#         fake_target = Variable(torch.zeros(real_images.size(0)).to(device))\n",
    "\n",
    "#         real_target = real_target.unsqueeze(1)\n",
    "#         fake_target = fake_target.unsqueeze(1)\n",
    "\n",
    "#         D_real_loss = discriminator_loss(discriminator(real_images), real_target)\n",
    "#         D_real_loss.backward()\n",
    "\n",
    "#         noise_vector = torch.randn(real_images.size(0), latent_dim, 1, 1, device=device)\n",
    "#         noise_vector = noise_vector.to(device)\n",
    "\n",
    "#         generated_image = generator(noise_vector)\n",
    "#         output = discriminator(generated_image.detach())\n",
    "#         D_fake_loss = discriminator_loss(output,  fake_target)\n",
    "\n",
    "#         D_fake_loss.backward()\n",
    "\n",
    "#         D_total_loss = D_real_loss + D_fake_loss\n",
    "#         D_loss_list.append(D_total_loss)\n",
    "\n",
    "#         D_optimizer.step()\n",
    "\n",
    "\n",
    "#         G_optimizer.zero_grad()\n",
    "#         G_loss = generator_loss(discriminator(generated_image), real_target)\n",
    "#         G_loss_list.append(G_loss)\n",
    "\n",
    "#         G_loss.backward()\n",
    "#         G_optimizer.step()\n",
    "\n",
    "\n",
    "#     print('Epoch: [%d/%d]: D_loss: %.3f, G_loss: %.3f' % (\n",
    "#             (epoch), num_epochs, torch.mean(torch.FloatTensor(D_loss_list)),\\\n",
    "#              torch.mean(torch.FloatTensor(G_loss_list))))\n",
    "\n",
    "#     D_loss_plot.append(torch.mean(torch.FloatTensor(D_loss_list)))\n",
    "#     G_loss_plot.append(torch.mean(torch.FloatTensor(G_loss_list)))\n",
    "#     if epoch > num_epochs*0.9:\n",
    "#         save_image(generated_image.data[:10], './images/sample_%d'%epoch + '.png', nrow=5, normalize=True)\n",
    "#         torch.save(generator.state_dict(), './t_weights/generator_epoch_%d.pth' % (epoch))\n",
    "#         torch.save(discriminator.state_dict(), './t_weights/discriminator_epoch_%d.pth' % (epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca8df7d1-dcba-42e3-8f64-ded1a6d600c3",
    "_uuid": "e58f2967-2382-4d0d-99af-f7b332da7356",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.174068,
     "end_time": "2021-10-09T14:16:51.448795",
     "exception": false,
     "start_time": "2021-10-09T14:16:51.274727",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h1 style=\"text-align:center;font-weight: bold\">Outputing Results</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "efdff7f4-06dd-40d7-b68c-dc237fbd5e42",
    "_kg_hide-output": true,
    "_uuid": "74ab055c-958e-4dba-982e-b37eee99999c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:18.015708Z",
     "iopub.status.busy": "2025-01-12T06:44:18.015394Z",
     "iopub.status.idle": "2025-01-12T06:44:18.029482Z",
     "shell.execute_reply": "2025-01-12T06:44:18.028763Z",
     "shell.execute_reply.started": "2025-01-12T06:44:18.015676Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.183417,
     "end_time": "2021-10-09T14:16:51.808241",
     "exception": false,
     "start_time": "2021-10-09T14:16:51.624824",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def getImagePaths(path):\n",
    "    image_names = []\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            fullpath = os.path.join(dirname, filename)\n",
    "            image_names.append(fullpath)\n",
    "    return image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1f0532aa-c026-4b89-958c-bf0d694a27eb",
    "_kg_hide-output": true,
    "_uuid": "62a98396-fef2-4cc2-b1cd-f0d10b0b0b3b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:18.030773Z",
     "iopub.status.busy": "2025-01-12T06:44:18.030495Z",
     "iopub.status.idle": "2025-01-12T06:44:18.334966Z",
     "shell.execute_reply": "2025-01-12T06:44:18.334280Z",
     "shell.execute_reply.started": "2025-01-12T06:44:18.030746Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.417852,
     "end_time": "2021-10-09T14:16:52.402334",
     "exception": false,
     "start_time": "2021-10-09T14:16:51.984482",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def display_multiple_img(images_paths):\n",
    "    # 计算自适应的行列数\n",
    "    num_images = len(images_paths)\n",
    "    cols = int(math.ceil(math.sqrt(num_images)))  # 列数 = 根号下的图像数量，四舍五入\n",
    "    rows = int(math.ceil(num_images / cols))  # 行数 = 图像数量 / 列数，四舍五入\n",
    "\n",
    "    # 设置图形大小，调整到适合的比例，增加图像的显示大小\n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(cols * 3, rows * 3))\n",
    "\n",
    "    # 遍历图像路径列表\n",
    "    for ind, image_path in enumerate(images_paths):\n",
    "        # 尝试读取并显示图像\n",
    "        try:\n",
    "            image = cv2.imread(image_path)  # 读取图像\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Image at {image_path} could not be loaded.\")\n",
    "\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # 转换为 RGB\n",
    "\n",
    "            ax.ravel()[ind].imshow(image)  # 显示图像\n",
    "            ax.ravel()[ind].set_axis_off()  # 隐藏轴\n",
    "        except Exception as e:\n",
    "            print(f\"Error displaying image at {image_path}: {e}\")\n",
    "\n",
    "    # 隐藏未使用的子图（如果图像少于网格数）\n",
    "    for i in range(num_images, rows * cols):\n",
    "        ax.ravel()[i].set_visible(False)\n",
    "\n",
    "    plt.tight_layout(pad=2.0)  # 增加子图间距\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a37b34f3-a661-41b5-998a-525dac5aae9a",
    "_kg_hide-output": true,
    "_uuid": "8cf75de8-95df-406b-86ea-fdddff2a4fdc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:18.336032Z",
     "iopub.status.busy": "2025-01-12T06:44:18.335778Z",
     "iopub.status.idle": "2025-01-12T06:44:21.735087Z",
     "shell.execute_reply": "2025-01-12T06:44:21.733716Z",
     "shell.execute_reply.started": "2025-01-12T06:44:18.336000Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 32.195267,
     "end_time": "2021-10-09T14:17:24.773111",
     "exception": false,
     "start_time": "2021-10-09T14:16:52.577844",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display_multiple_img(getImagePaths(\"./images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "76507487-647c-4dcd-b04a-6f5321ff078c",
    "_uuid": "b34c7603-34db-4efc-9e25-54eaea4b671d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:21.737128Z",
     "iopub.status.busy": "2025-01-12T06:44:21.736643Z",
     "iopub.status.idle": "2025-01-12T06:44:25.148269Z",
     "shell.execute_reply": "2025-01-12T06:44:25.147249Z",
     "shell.execute_reply.started": "2025-01-12T06:44:21.737065Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "325aaaee-3f89-4a9c-bc3b-04979eedafe0",
    "_uuid": "4d3c624d-b449-4d94-941f-cc41041cb802",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:25.149572Z",
     "iopub.status.busy": "2025-01-12T06:44:25.149313Z",
     "iopub.status.idle": "2025-01-12T06:44:27.892226Z",
     "shell.execute_reply": "2025-01-12T06:44:27.891458Z",
     "shell.execute_reply.started": "2025-01-12T06:44:25.149553Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "real_images_dir = \"./train\"\n",
    "generated_images_dir = \"./generated_images\"\n",
    "os.makedirs(real_images_dir, exist_ok=True)\n",
    "os.makedirs(generated_images_dir, exist_ok=True)\n",
    "\n",
    "generator = Generator()  # 使用你定义的生成器类\n",
    "# generator.load_state_dict(torch.load(f'./t_weights/generator_epoch_{num_epochs}.pth'))  # 加载最后一轮的生成器权重\n",
    "generator.load_state_dict(torch.load(f\"./t_weights/best_generator.pth\"))\n",
    "generator.eval()\n",
    "\n",
    "\n",
    "def generate_images(generator, num_images, latent_dim, save_dir):\n",
    "    generator.eval()\n",
    "    noise_vector = torch.randn(num_images, latent_dim, 1, 1)\n",
    "    with torch.no_grad():\n",
    "        generated_images = generator(noise_vector)\n",
    "    generated_images = torch.nn.functional.interpolate(generated_images, size=(64, 64))\n",
    "\n",
    "    # 保存每张图像到指定目录\n",
    "    for i in range(num_images):\n",
    "        save_path = os.path.join(save_dir, f\"generated_image_{i + 1:03d}.png\")\n",
    "        save_image(generated_images[i], save_path, normalize=True)\n",
    "\n",
    "\n",
    "def save_real_images(dataset_path, save_dir, num_images=50):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((64, 64)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "        ]\n",
    "    )\n",
    "    real_dataset = ImageFolder(root=dataset_path, transform=transform)\n",
    "    real_loader = DataLoader(real_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # 保存前 num_images 的真实图像\n",
    "    for i, (image, _) in enumerate(real_loader):\n",
    "        if i >= num_images:\n",
    "            break\n",
    "        save_path = os.path.join(save_dir, f\"real_image_{i + 1:03d}.png\")\n",
    "        save_image(image[0], save_path, normalize=True)\n",
    "\n",
    "\n",
    "generate_images(\n",
    "    generator, num_images=200, latent_dim=latent_dim, save_dir=generated_images_dir\n",
    ")\n",
    "\n",
    "path_to_real_dataset = \"./real_images\"\n",
    "os.makedirs(path_to_real_dataset, exist_ok=True)\n",
    "save_real_images(real_images_dir, path_to_real_dataset, num_images=200)\n",
    "\n",
    "# 提示用户使用 pytorch-fid 工具\n",
    "print(f\"Run the following command to compute FID:\")\n",
    "print(f\"pytorch-fid {path_to_real_dataset} {generated_images_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "398a53aa-9664-41e8-88b8-80c7ee728e1a",
    "_uuid": "e5f13b2a-5fc6-4458-869c-55e5c0236cd6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:27.893335Z",
     "iopub.status.busy": "2025-01-12T06:44:27.893050Z",
     "iopub.status.idle": "2025-01-12T06:44:34.461170Z",
     "shell.execute_reply": "2025-01-12T06:44:34.459975Z",
     "shell.execute_reply.started": "2025-01-12T06:44:27.893312Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display_multiple_img(getImagePaths(\"./generated_images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "64878cf4-4e54-4128-b187-4a3b1cd6395a",
    "_uuid": "01581491-14bd-421c-99f4-cab14607d6be",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:34.462448Z",
     "iopub.status.busy": "2025-01-12T06:44:34.462138Z",
     "iopub.status.idle": "2025-01-12T06:44:50.224051Z",
     "shell.execute_reply": "2025-01-12T06:44:50.222904Z",
     "shell.execute_reply.started": "2025-01-12T06:44:34.462422Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python -m pytorch_fid  ./real_images ./generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4cb9b792-f680-4280-912b-6d370a74b435",
    "_uuid": "8137045c-565d-4809-8dba-a5316aab9354",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:50.225954Z",
     "iopub.status.busy": "2025-01-12T06:44:50.225607Z",
     "iopub.status.idle": "2025-01-12T06:44:56.334459Z",
     "shell.execute_reply": "2025-01-12T06:44:56.333751Z",
     "shell.execute_reply.started": "2025-01-12T06:44:50.225921Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generate_images(\n",
    "    generator, num_images=500, latent_dim=latent_dim, save_dir=generated_images_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a75d196c-395f-4471-bfa1-4da449ca62b0",
    "_uuid": "e08f1af8-2c44-4d30-aefc-62e774da513e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:56.335379Z",
     "iopub.status.busy": "2025-01-12T06:44:56.335167Z",
     "iopub.status.idle": "2025-01-12T06:44:56.624474Z",
     "shell.execute_reply": "2025-01-12T06:44:56.623390Z",
     "shell.execute_reply.started": "2025-01-12T06:44:56.335354Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r generated_images.zip ./generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e759dda1-2feb-4f6f-9210-ea2c76100ec4",
    "_uuid": "8ef37cd3-e109-4a97-afe4-ba5dd1bcc77c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5947813,
     "sourceId": 10287936,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
