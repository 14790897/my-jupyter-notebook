{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3cfda68a-d94f-4869-af30-3810bbda792d",
    "_uuid": "f6a0192a-068c-4794-a558-92699409fd50",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.024671,
     "end_time": "2021-10-09T06:31:15.364456",
     "exception": false,
     "start_time": "2021-10-09T06:31:15.339785",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h1 style=\"text-align:center;font-weight: bold\">DCGAN (Deep Convolutional GAN)</h1>\n",
    "    <h3 style=\"text-align:left;font-weight: bold\">DCGAN is a type of GAN that uses deep convolutional networks for both the generator and discriminator. It was introduced by Radford et al. in 2015 and established architectural guidelines that made training GANs more stable. Key features include using strided convolutions instead of pooling, batch normalization, and using ReLU/LeakyReLU activations.</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主要改动说明 (What Changed)\n",
    "\n",
    "本 notebook 已从混合架构改为**标准 DCGAN 实现**:\n",
    "\n",
    "## 1. Generator 改动\n",
    "\n",
    "- **之前**: 使用 ResNet 残差块结构\n",
    "- **现在**: 标准 DCGAN 生成器，使用 ConvTranspose2d 层\n",
    "- **架构**: latent(100) → 4×4 → 8×8 → 16×16 → 32×32 → 64×64\n",
    "\n",
    "## 2. Discriminator 改动\n",
    "\n",
    "- **之前**: 使用 Spectral Normalization\n",
    "- **现在**: 标准 DCGAN 判别器，使用 BatchNorm2d\n",
    "- **架构**: 64×64 → 32×32 → 16×16 → 8×8 → 4×4 → 1\n",
    "\n",
    "## 3. Loss Function 改动\n",
    "\n",
    "- **之前**: WGAN-GP loss (Wasserstein 距离 + 梯度惩罚)\n",
    "- **现在**: Binary Cross Entropy Loss (标准 GAN loss)\n",
    "\n",
    "## 4. Training Loop 改动\n",
    "\n",
    "- **之前**: 使用 n_critic 训练策略，有梯度惩罚\n",
    "- **现在**: 标准 DCGAN 训练，D 和 G 每个 batch 都更新一次\n",
    "\n",
    "## 5. 参数调整\n",
    "\n",
    "- Batch size: 16 → 128\n",
    "- Learning rate: 保持 0.0002 (DCGAN 推荐值)\n",
    "- Beta1: 0.5 (DCGAN 推荐值)\n",
    "- Latent dim: 128 → 100 (DCGAN 标准)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "185b050c-45f1-4b73-a064-4d4073816aa5",
    "_uuid": "c17b1ae3-930b-4b9f-b13e-f329f70b4086",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:03.639124Z",
     "iopub.status.busy": "2025-01-12T06:34:03.638765Z",
     "iopub.status.idle": "2025-01-12T06:34:16.282299Z",
     "shell.execute_reply": "2025-01-12T06:34:16.281612Z",
     "shell.execute_reply.started": "2025-01-12T06:34:03.639072Z"
    },
    "id": "yoj6U2rmjiS-",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.625925,
     "end_time": "2021-10-09T06:31:24.764729",
     "exception": false,
     "start_time": "2021-10-09T06:31:23.138804",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torchsummary\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8b33fe96-0dab-4d66-b95c-5c981238f4c6",
    "_uuid": "90dec837-50c8-43cc-8c40-3549d5801e41",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:16.316158Z",
     "iopub.status.busy": "2025-01-12T06:34:16.315904Z",
     "iopub.status.idle": "2025-01-12T06:34:16.369325Z",
     "shell.execute_reply": "2025-01-12T06:34:16.368515Z",
     "shell.execute_reply.started": "2025-01-12T06:34:16.316131Z"
    },
    "id": "xVXC_q2ekuf8",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.079089,
     "end_time": "2021-10-09T06:31:24.988503",
     "exception": false,
     "start_time": "2021-10-09T06:31:24.909414",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 128\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 200\n",
    "image_size = 64\n",
    "latent_dim = 100\n",
    "ngf = 64  # Number of generator filters\n",
    "ndf = 64  # Number of discriminator filters\n",
    "nc = 1  # Number of channels (1 for grayscale, 3 for RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "88cfb87c-2c50-47bc-9713-23327eb190ab",
    "_uuid": "6f33ed63-0643-42c1-84e7-41a230203cbd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:16.389651Z",
     "iopub.status.busy": "2025-01-12T06:34:16.389327Z",
     "iopub.status.idle": "2025-01-12T06:34:24.236402Z",
     "shell.execute_reply": "2025-01-12T06:34:24.235562Z",
     "shell.execute_reply.started": "2025-01-12T06:34:16.389623Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Source directory with your images\n",
    "source_dir = \"/kaggle/input/efficientnet-data/my_label_data/0\"\n",
    "target_dir = \"./train/data\"\n",
    "\n",
    "# Create target directory\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Copy images to training directory\n",
    "# Adjust these paths according to your actual data location\n",
    "if os.path.exists(source_dir):\n",
    "    shutil.copytree(source_dir, target_dir, dirs_exist_ok=True)\n",
    "    print(f\"Copied images from {source_dir}\")\n",
    "else:\n",
    "    print(f\"Warning: Source directory {source_dir} not found\")\n",
    "\n",
    "# Count images\n",
    "image_count = sum(\n",
    "    1\n",
    "    for file_name in os.listdir(target_dir)\n",
    "    if file_name.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".tif\"))\n",
    ")\n",
    "\n",
    "print(f\"Total images in training directory: {image_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c112a932-0942-41d7-8e10-ba77dc4a8bbf",
    "_uuid": "b049533a-c11b-4be7-9f12-8d45ece96dee",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:24.237433Z",
     "iopub.status.busy": "2025-01-12T06:34:24.237151Z",
     "iopub.status.idle": "2025-01-12T06:34:24.247863Z",
     "shell.execute_reply": "2025-01-12T06:34:24.247128Z",
     "shell.execute_reply.started": "2025-01-12T06:34:24.237411Z"
    },
    "id": "rmKRUtX6kwt1",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 12.148366,
     "end_time": "2021-10-09T06:31:37.214299",
     "exception": false,
     "start_time": "2021-10-09T06:31:25.065933",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),  # Normalize to [-1, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=\"./train\", transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(train_dataset)}\")\n",
    "print(f\"Number of batches: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eb338297-2160-4deb-9a0e-e914e251b4da",
    "_uuid": "7069c276-e014-4279-ac92-d7be7d48f8a4",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.025809,
     "end_time": "2021-10-09T06:31:37.266513",
     "exception": false,
     "start_time": "2021-10-09T06:31:37.240704",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h1 style=\"text-align:center;font-weight: bold;\">Exploratory Data Analysis</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d7d2bd2c-77d8-4f58-ba96-8f650e57469c",
    "_uuid": "969de3ef-3d59-4d2b-851b-f4f9e7aa87e0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:24.250644Z",
     "iopub.status.busy": "2025-01-12T06:34:24.250435Z",
     "iopub.status.idle": "2025-01-12T06:34:24.710678Z",
     "shell.execute_reply": "2025-01-12T06:34:24.708328Z",
     "shell.execute_reply.started": "2025-01-12T06:34:24.250626Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034789,
     "end_time": "2021-10-09T06:31:37.327581",
     "exception": false,
     "start_time": "2021-10-09T06:31:37.292792",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "# 显示图像的函数\n",
    "def show_images(images, nrow=8, figsize=(10, 10)):\n",
    "    # 创建图像网格\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_xticks([])  # 隐藏x轴刻度\n",
    "    ax.set_yticks([])  # 隐藏y轴刻度\n",
    "\n",
    "    # 将图片网格的大小调整并转置为 (height, width, channels)\n",
    "    grid_img = make_grid(images, nrow=nrow).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # 显示图片\n",
    "    ax.imshow(grid_img)\n",
    "\n",
    "\n",
    "# 显示批次图像的函数\n",
    "def show_batch(dl, n_images=64, nrow=8):\n",
    "    # 只显示部分图像\n",
    "    for images, _ in dl:\n",
    "        # 只取前 n_images 张图像\n",
    "        images = images[:n_images]\n",
    "        show_images(images, nrow=nrow)\n",
    "        break  # 只显示一个批次的图像\n",
    "\n",
    "\n",
    "# 使用 train_loader 来展示图像\n",
    "show_batch(train_loader, n_images=64, nrow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "67a898fe-caa2-4870-bd2b-4fc6c24a2476",
    "_uuid": "1750cd4d-e755-4cb4-9af0-7b44254896f9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:24.717565Z",
     "iopub.status.busy": "2025-01-12T06:34:24.714841Z",
     "iopub.status.idle": "2025-01-12T06:34:24.726048Z",
     "shell.execute_reply": "2025-01-12T06:34:24.724925Z",
     "shell.execute_reply.started": "2025-01-12T06:34:24.717521Z"
    },
    "id": "0ImLVM7lk2du",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.04636,
     "end_time": "2021-10-09T06:31:39.249683",
     "exception": false,
     "start_time": "2021-10-09T06:31:39.203323",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# These parameters are now defined in the configuration cell above\n",
    "print(f\"Image channels: {nc}\")\n",
    "print(f\"Image size: {image_size}x{image_size}\")\n",
    "print(f\"Latent dimension: {latent_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5277c9ec-490a-4952-af78-85e444637949",
    "_uuid": "b5ab7922-b70a-4ba4-9b2e-fcae568e7bfc",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.037989,
     "end_time": "2021-10-09T06:31:39.325346",
     "exception": false,
     "start_time": "2021-10-09T06:31:39.287357",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h2 style=\"text-align:center;font-weight: bold;\">Initializing Weights</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3318f1fe-ede0-4a2b-a17f-8616cb5c7b64",
    "_uuid": "9429989a-2724-46a7-86ef-df8158fad3b3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:24.730013Z",
     "iopub.status.busy": "2025-01-12T06:34:24.729569Z",
     "iopub.status.idle": "2025-01-12T06:34:24.741828Z",
     "shell.execute_reply": "2025-01-12T06:34:24.741240Z",
     "shell.execute_reply.started": "2025-01-12T06:34:24.729975Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.046865,
     "end_time": "2021-10-09T06:31:39.485146",
     "exception": false,
     "start_time": "2021-10-09T06:31:39.438281",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        torch.nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key DCGAN Architecture Guidelines\n",
    "\n",
    "Following the DCGAN paper (Radford et al., 2015):\n",
    "\n",
    "1. **Replace pooling layers** with strided convolutions (discriminator) and fractional-strided/transposed convolutions (generator)\n",
    "2. **Use batchnorm** in both the generator and the discriminator\n",
    "3. **Remove fully connected hidden layers** for deeper architectures\n",
    "4. **Use ReLU activation** in generator for all layers except the output, which uses Tanh\n",
    "5. **Use LeakyReLU activation** in the discriminator for all layers\n",
    "6. **Initialize weights** from a Normal distribution with mean=0, std=0.02\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a6c5341a-4d5b-4e98-a0f4-e6b87df89d15",
    "_uuid": "16bca70b-5df7-40cf-9e98-a729f5149c77",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.037616,
     "end_time": "2021-10-09T06:31:39.560468",
     "exception": false,
     "start_time": "2021-10-09T06:31:39.522852",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h2 style=\"text-align:center;font-weight: bold;\">Generator Network</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "683afb83-a4b3-42f7-9be3-4864658e9634",
    "_uuid": "e72d7aaa-ea60-43a2-81f5-a8cd84f83596",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:24.742800Z",
     "iopub.status.busy": "2025-01-12T06:34:24.742562Z",
     "iopub.status.idle": "2025-01-12T06:34:24.758634Z",
     "shell.execute_reply": "2025-01-12T06:34:24.757816Z",
     "shell.execute_reply.started": "2025-01-12T06:34:24.742768Z"
    },
    "id": "_gw3SMN7jtOB",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.051132,
     "end_time": "2021-10-09T06:31:39.649246",
     "exception": false,
     "start_time": "2021-10-09T06:31:39.598114",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    DCGAN Generator\n",
    "    Input: latent vector z of dimension (latent_dim, 1, 1)\n",
    "    Output: Generated image of size (nc, 64, 64)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is latent_dim x 1 x 1\n",
    "            nn.ConvTranspose2d(latent_dim, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # State size: (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # State size: (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # State size: (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # State size: (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "            # State size: (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9a44af85-878c-4916-a3b3-5949afc423ce",
    "_uuid": "d01c19d6-8a0e-4fc3-97a8-392a6fb1b82d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:24.759643Z",
     "iopub.status.busy": "2025-01-12T06:34:24.759436Z",
     "iopub.status.idle": "2025-01-12T06:34:25.036508Z",
     "shell.execute_reply": "2025-01-12T06:34:25.035660Z",
     "shell.execute_reply.started": "2025-01-12T06:34:24.759626Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.374826,
     "end_time": "2021-10-09T06:31:43.061517",
     "exception": false,
     "start_time": "2021-10-09T06:31:39.686691",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "generator.apply(weights_init)\n",
    "print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "db59897a-0fc2-432f-84ff-383e71116d45",
    "_uuid": "d99d6a53-2b0a-49a2-936c-c43c7f831b23",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:25.037548Z",
     "iopub.status.busy": "2025-01-12T06:34:25.037336Z",
     "iopub.status.idle": "2025-01-12T06:34:25.703458Z",
     "shell.execute_reply": "2025-01-12T06:34:25.702520Z",
     "shell.execute_reply.started": "2025-01-12T06:34:25.037529Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.616425,
     "end_time": "2021-10-09T06:31:43.756299",
     "exception": false,
     "start_time": "2021-10-09T06:31:43.139874",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "summary(generator, (latent_dim, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "018303e4-119b-4235-8a78-9af0e92144f7",
    "_uuid": "0fbdff18-cfe8-49f2-8094-9fa0af04012d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.038779,
     "end_time": "2021-10-09T06:31:43.835699",
     "exception": false,
     "start_time": "2021-10-09T06:31:43.79692",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h2 style=\"text-align:center;font-weight: bold;\">Descriminator Network</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8dc7f45e-91e8-47d4-8908-0ef0e052e7ca",
    "_uuid": "21e70dc5-1531-4e0f-872a-d83a1e9128dc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:25.704989Z",
     "iopub.status.busy": "2025-01-12T06:34:25.704654Z",
     "iopub.status.idle": "2025-01-12T06:34:25.711359Z",
     "shell.execute_reply": "2025-01-12T06:34:25.710514Z",
     "shell.execute_reply.started": "2025-01-12T06:34:25.704955Z"
    },
    "id": "xPEMXbaJCPsQ",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.052823,
     "end_time": "2021-10-09T06:31:43.927067",
     "exception": false,
     "start_time": "2021-10-09T06:31:43.874244",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    DCGAN Discriminator\n",
    "    Input: Image of size (nc, 64, 64)\n",
    "    Output: Single scalar value (probability of being real)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size: (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size: (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size: (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size: (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "            # State size: 1 x 1 x 1\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "daf4e64b-b6d7-4408-9b12-f8d40028e6be",
    "_uuid": "3764bb87-4a65-45cf-bb52-a1d720f201aa",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:25.712354Z",
     "iopub.status.busy": "2025-01-12T06:34:25.712072Z",
     "iopub.status.idle": "2025-01-12T06:34:25.781981Z",
     "shell.execute_reply": "2025-01-12T06:34:25.781263Z",
     "shell.execute_reply.started": "2025-01-12T06:34:25.712332Z"
    },
    "id": "1HJv-CnSkIuN",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.071596,
     "end_time": "2021-10-09T06:31:44.037229",
     "exception": false,
     "start_time": "2021-10-09T06:31:43.965633",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "discriminator.apply(weights_init)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c7d6c54e-e089-41f0-af22-4ac6cc590584",
    "_uuid": "bf9e8634-0b0f-491a-95c8-b1320269679f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:25.783030Z",
     "iopub.status.busy": "2025-01-12T06:34:25.782779Z",
     "iopub.status.idle": "2025-01-12T06:34:25.974784Z",
     "shell.execute_reply": "2025-01-12T06:34:25.974038Z",
     "shell.execute_reply.started": "2025-01-12T06:34:25.783009Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.0621,
     "end_time": "2021-10-09T06:31:44.143231",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.081131",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "summary(discriminator, (nc, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0b94231b-b024-4b15-94e8-71971b8ad725",
    "_uuid": "a188ab9d-59fc-4184-8cd1-5aea5068cf96",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:25.975704Z",
     "iopub.status.busy": "2025-01-12T06:34:25.975502Z",
     "iopub.status.idle": "2025-01-12T06:34:25.979250Z",
     "shell.execute_reply": "2025-01-12T06:34:25.978563Z",
     "shell.execute_reply.started": "2025-01-12T06:34:25.975686Z"
    },
    "id": "RFxQC7T0laZi",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.045481,
     "end_time": "2021-10-09T06:31:44.228253",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.182772",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Use Binary Cross Entropy Loss for DCGAN\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "64b31e26-6dfb-4ba5-a8cc-488762747480",
    "_uuid": "1e0132b4-158d-47ee-bd1c-3af18c3f4d6b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.038516,
     "end_time": "2021-10-09T06:31:44.390559",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.352043",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "## Loss Functions for DCGAN\n",
    "\n",
    "In DCGAN, we use Binary Cross Entropy (BCE) loss:\n",
    "\n",
    "- **Discriminator**: Tries to classify real images as 1 and fake images as 0\n",
    "- **Generator**: Tries to fool the discriminator by making it classify fake images as 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c76b96a6-466f-42be-94f7-c3a75a9dd855",
    "_uuid": "0ad0c93b-84bc-4e87-80c3-e29839e807f3",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.063915,
     "end_time": "2021-10-09T06:31:44.635401",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.571486",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "## Labels for Training\n",
    "\n",
    "- Real images are labeled as 1\n",
    "- Fake (generated) images are labeled as 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "49789e9f-4126-456b-b932-7858c7ec3cea",
    "_uuid": "b0d59200-95d1-48b3-a56c-a5eb94932909",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:26.038017Z",
     "iopub.status.busy": "2025-01-12T06:34:26.037827Z",
     "iopub.status.idle": "2025-01-12T06:34:26.051640Z",
     "shell.execute_reply": "2025-01-12T06:34:26.050808Z",
     "shell.execute_reply.started": "2025-01-12T06:34:26.038001Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.072788,
     "end_time": "2021-10-09T06:31:44.772757",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.699969",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fixed noise for visualization\n",
    "fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)\n",
    "\n",
    "# Labels\n",
    "real_label = 1.0\n",
    "fake_label = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3ce1f5d3-f52b-471e-8d38-f730360cbf3e",
    "_uuid": "6898a4d4-d37d-4bd5-aed6-a8cf777f723e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:26.052698Z",
     "iopub.status.busy": "2025-01-12T06:34:26.052479Z",
     "iopub.status.idle": "2025-01-12T06:34:26.066280Z",
     "shell.execute_reply": "2025-01-12T06:34:26.065351Z",
     "shell.execute_reply.started": "2025-01-12T06:34:26.052679Z"
    },
    "id": "sis4zEVQkLf_",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.077416,
     "end_time": "2021-10-09T06:31:44.914779",
     "exception": false,
     "start_time": "2021-10-09T06:31:44.837363",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Setup Adam optimizers for both G and D\n",
    "# Using beta1=0.5 as suggested in DCGAN paper\n",
    "optimizerD = optim.Adam(\n",
    "    discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999)\n",
    ")\n",
    "optimizerG = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "864f35ec-4289-4139-8030-4c7c4472865e",
    "_uuid": "2a853f52-3849-4fdc-a779-d51eb1642260",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.040677,
     "end_time": "2021-10-09T06:31:46.648014",
     "exception": false,
     "start_time": "2021-10-09T06:31:46.607337",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h2 style=\"text-align:center;font-weight: bold;\">Training our network</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3d04ed1d-7beb-4562-a1aa-8f620d60c7dd",
    "_uuid": "484b32b7-3286-4f89-b774-239bb714b94d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:34:26.067396Z",
     "iopub.status.busy": "2025-01-12T06:34:26.067085Z",
     "iopub.status.idle": "2025-01-12T06:44:17.687251Z",
     "shell.execute_reply": "2025-01-12T06:44:17.686233Z",
     "shell.execute_reply.started": "2025-01-12T06:34:26.067368Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Lists to keep track of progress\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "img_list = []\n",
    "iters = 0\n",
    "\n",
    "# Create directories for saving results\n",
    "os.makedirs(\"./dcgan_weights\", exist_ok=True)\n",
    "os.makedirs(\"./dcgan_images\", exist_ok=True)\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_images, _) in enumerate(train_loader):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        discriminator.zero_grad()\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        label = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "\n",
    "        # Forward pass real batch through D\n",
    "        output = discriminator(real_images)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(batch_size, latent_dim, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = generator(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = discriminator(fake.detach())\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        generator.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = discriminator(fake)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print(\n",
    "                f\"[{epoch}/{num_epochs}][{i}/{len(train_loader)}] \"\n",
    "                f\"Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} \"\n",
    "                f\"D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}\"\n",
    "            )\n",
    "\n",
    "        iters += 1\n",
    "\n",
    "    # Check how the generator is doing by saving G's output on fixed_noise\n",
    "    if (epoch % 10 == 0) or (epoch == num_epochs - 1):\n",
    "        with torch.no_grad():\n",
    "            fake = generator(fixed_noise).detach().cpu()\n",
    "        save_image(\n",
    "            fake,\n",
    "            f\"./dcgan_images/fake_samples_epoch_{epoch:03d}.png\",\n",
    "            normalize=True,\n",
    "            nrow=8,\n",
    "        )\n",
    "\n",
    "    # Save model checkpoints\n",
    "    if (epoch % 50 == 0) or (epoch == num_epochs - 1):\n",
    "        torch.save(\n",
    "            generator.state_dict(), f\"./dcgan_weights/generator_epoch_{epoch}.pth\"\n",
    "        )\n",
    "        torch.save(\n",
    "            discriminator.state_dict(),\n",
    "            f\"./dcgan_weights/discriminator_epoch_{epoch}.pth\",\n",
    "        )\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7225009f-6597-4411-9a71-718da7602b42",
    "_uuid": "da4b614d-4497-463d-86b6-d12c0a124466",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:17.688707Z",
     "iopub.status.busy": "2025-01-12T06:44:17.688454Z",
     "iopub.status.idle": "2025-01-12T06:44:18.007319Z",
     "shell.execute_reply": "2025-01-12T06:44:18.006452Z",
     "shell.execute_reply.started": "2025-01-12T06:44:17.688685Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot the training losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"G\")\n",
    "plt.plot(D_losses, label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca8df7d1-dcba-42e3-8f64-ded1a6d600c3",
    "_uuid": "e58f2967-2382-4d0d-99af-f7b332da7356",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.174068,
     "end_time": "2021-10-09T14:16:51.448795",
     "exception": false,
     "start_time": "2021-10-09T14:16:51.274727",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "<h1 style=\"text-align:center;font-weight: bold\">Outputing Results</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "efdff7f4-06dd-40d7-b68c-dc237fbd5e42",
    "_kg_hide-output": true,
    "_uuid": "74ab055c-958e-4dba-982e-b37eee99999c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:18.015708Z",
     "iopub.status.busy": "2025-01-12T06:44:18.015394Z",
     "iopub.status.idle": "2025-01-12T06:44:18.029482Z",
     "shell.execute_reply": "2025-01-12T06:44:18.028763Z",
     "shell.execute_reply.started": "2025-01-12T06:44:18.015676Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.183417,
     "end_time": "2021-10-09T14:16:51.808241",
     "exception": false,
     "start_time": "2021-10-09T14:16:51.624824",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def getImagePaths(path):\n",
    "    \"\"\"Get all image file paths from a directory\"\"\"\n",
    "    image_names = []\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                fullpath = os.path.join(dirname, filename)\n",
    "                image_names.append(fullpath)\n",
    "    return sorted(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1f0532aa-c026-4b89-958c-bf0d694a27eb",
    "_kg_hide-output": true,
    "_uuid": "62a98396-fef2-4cc2-b1cd-f0d10b0b0b3b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:18.030773Z",
     "iopub.status.busy": "2025-01-12T06:44:18.030495Z",
     "iopub.status.idle": "2025-01-12T06:44:18.334966Z",
     "shell.execute_reply": "2025-01-12T06:44:18.334280Z",
     "shell.execute_reply.started": "2025-01-12T06:44:18.030746Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.417852,
     "end_time": "2021-10-09T14:16:52.402334",
     "exception": false,
     "start_time": "2021-10-09T14:16:51.984482",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def display_multiple_img(images_paths):\n",
    "    # 计算自适应的行列数\n",
    "    num_images = len(images_paths)\n",
    "    cols = int(math.ceil(math.sqrt(num_images)))  # 列数 = 根号下的图像数量，四舍五入\n",
    "    rows = int(math.ceil(num_images / cols))  # 行数 = 图像数量 / 列数，四舍五入\n",
    "\n",
    "    # 设置图形大小，调整到适合的比例，增加图像的显示大小\n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(cols * 3, rows * 3))\n",
    "\n",
    "    # 遍历图像路径列表\n",
    "    for ind, image_path in enumerate(images_paths):\n",
    "        # 尝试读取并显示图像\n",
    "        try:\n",
    "            image = cv2.imread(image_path)  # 读取图像\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Image at {image_path} could not be loaded.\")\n",
    "\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # 转换为 RGB\n",
    "\n",
    "            ax.ravel()[ind].imshow(image)  # 显示图像\n",
    "            ax.ravel()[ind].set_axis_off()  # 隐藏轴\n",
    "        except Exception as e:\n",
    "            print(f\"Error displaying image at {image_path}: {e}\")\n",
    "\n",
    "    # 隐藏未使用的子图（如果图像少于网格数）\n",
    "    for i in range(num_images, rows * cols):\n",
    "        ax.ravel()[i].set_visible(False)\n",
    "\n",
    "    plt.tight_layout(pad=2.0)  # 增加子图间距\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a37b34f3-a661-41b5-998a-525dac5aae9a",
    "_kg_hide-output": true,
    "_uuid": "8cf75de8-95df-406b-86ea-fdddff2a4fdc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:18.336032Z",
     "iopub.status.busy": "2025-01-12T06:44:18.335778Z",
     "iopub.status.idle": "2025-01-12T06:44:21.735087Z",
     "shell.execute_reply": "2025-01-12T06:44:21.733716Z",
     "shell.execute_reply.started": "2025-01-12T06:44:18.336000Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 32.195267,
     "end_time": "2021-10-09T14:17:24.773111",
     "exception": false,
     "start_time": "2021-10-09T14:16:52.577844",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display_multiple_img(getImagePaths(\"./dcgan_images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "325aaaee-3f89-4a9c-bc3b-04979eedafe0",
    "_uuid": "4d3c624d-b449-4d94-941f-cc41041cb802",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:25.149572Z",
     "iopub.status.busy": "2025-01-12T06:44:25.149313Z",
     "iopub.status.idle": "2025-01-12T06:44:27.892226Z",
     "shell.execute_reply": "2025-01-12T06:44:27.891458Z",
     "shell.execute_reply.started": "2025-01-12T06:44:25.149553Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate images using the trained generator\n",
    "generated_images_dir = \"./dcgan_generated\"\n",
    "os.makedirs(generated_images_dir, exist_ok=True)\n",
    "\n",
    "# Load the best generator model\n",
    "generator_eval = Generator().to(device)\n",
    "generator_eval.load_state_dict(torch.load(\"./dcgan_weights/generator_epoch_199.pth\"))\n",
    "generator_eval.eval()\n",
    "\n",
    "print(\"Generating images...\")\n",
    "num_images = 100\n",
    "with torch.no_grad():\n",
    "    for i in range(num_images):\n",
    "        noise = torch.randn(1, latent_dim, 1, 1, device=device)\n",
    "        fake_image = generator_eval(noise)\n",
    "        save_path = os.path.join(generated_images_dir, f\"generated_{i:04d}.png\")\n",
    "        save_image(fake_image, save_path, normalize=True)\n",
    "\n",
    "print(f\"Generated {num_images} images in {generated_images_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "398a53aa-9664-41e8-88b8-80c7ee728e1a",
    "_uuid": "e5f13b2a-5fc6-4458-869c-55e5c0236cd6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-12T06:44:27.893335Z",
     "iopub.status.busy": "2025-01-12T06:44:27.893050Z",
     "iopub.status.idle": "2025-01-12T06:44:34.461170Z",
     "shell.execute_reply": "2025-01-12T06:44:34.459975Z",
     "shell.execute_reply.started": "2025-01-12T06:44:27.893312Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display_multiple_img(getImagePaths(generated_images_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate More Images (Optional)\n",
    "\n",
    "You can generate more images by running the code below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a larger batch of images\n",
    "num_additional = 500\n",
    "print(f\"Generating {num_additional} more images...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_additional):\n",
    "        noise = torch.randn(1, latent_dim, 1, 1, device=device)\n",
    "        fake_image = generator_eval(noise)\n",
    "        save_path = os.path.join(generated_images_dir, f\"generated_{100+i:04d}.png\")\n",
    "        save_image(fake_image, save_path, normalize=True)\n",
    "\n",
    "print(f\"Total images generated: {100 + num_additional}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implements a standard DCGAN (Deep Convolutional GAN) with the following key components:\n",
    "\n",
    "1. **Generator**: Uses transposed convolutions to upsample from a latent vector (100-dim) to a 64x64 image\n",
    "2. **Discriminator**: Uses strided convolutions to downsample a 64x64 image to a single probability score\n",
    "3. **Training**: Uses Binary Cross-Entropy loss for both networks\n",
    "4. **Architecture Guidelines** (following DCGAN paper):\n",
    "   - Replace pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator)\n",
    "   - Use batch normalization in both networks\n",
    "   - Remove fully connected hidden layers\n",
    "   - Use ReLU activation in generator (except output layer which uses Tanh)\n",
    "   - Use LeakyReLU activation in discriminator\n",
    "\n",
    "Key differences from other GAN variants:\n",
    "\n",
    "- **Not using WGAN-GP**: No gradient penalty or Wasserstein distance\n",
    "- **Not using Spectral Normalization**: Standard batch normalization instead\n",
    "- **BCE Loss**: Classic GAN loss function, not hinge loss or other variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e759dda1-2feb-4f6f-9210-ea2c76100ec4",
    "_uuid": "8ef37cd3-e109-4a97-afe4-ba5dd1bcc77c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5947813,
     "sourceId": 10287936,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
